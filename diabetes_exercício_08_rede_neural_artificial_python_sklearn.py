# -*- coding: utf-8 -*-
"""Diabetes - Exercício - 08 - Rede Neural Artificial - Python - SkLearn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qwp3eDrvDZq0vwDR9MDIkJXIWEQa61EY

# Treinamento

### Carregando Arquivo de Treinamento (.csv)
"""

import pandas as pd
# Carregando dados do arquivo CSV
#url = 'https://raw.githubusercontent.com/alcidesbenicasa/IA---2020.1---Exerc-cio---06---Rede-Neural-Artificial/main/dados_pacientes_treinamento.csv'
url = 'https://raw.githubusercontent.com/lauro-ss/Exercicio-IA-Rede-Neural/main/base_de_dados_diabetes.csv'

#toLear
base_Treinamento = pd.read_csv(url,sep=',', encoding = 'latin1', nrows=650).values

print("---------------------------------")
print("Dados dos Pacientes - TREINAMENTO")
print("---------------------------------")
print(base_Treinamento)
print("---------------------------------")

# Extração dos Atributos a serem utilizadas pela rede
# numero e gravidez ignroado
print("Atributos de Entrada")
print("---------------------------------")
print(base_Treinamento[:,1:8])

print("----------------------------")
print("Classificação Supervisionada")
print("----------------------------")
print(base_Treinamento[:, 8])

"""### Pré-processamento de Dados"""

import numpy as np 
from sklearn import preprocessing

# Binarizador de rótulo
lb = preprocessing.LabelBinarizer()


X_train = np.array(base_Treinamento[:,1:8])
scaler = preprocessing.StandardScaler().fit(X_train)


atributos_norm = scaler.transform(X_train)


#Atributos categóricos com valores pequenas e grandes

#lb.fit(['grandes', 'pequenas'])
#manchas = lb.transform(base_Treinamento[:,3])

#Atributos categóricos com valores saudável e doente

#lb.fit(['saudável', 'doente'])
#classes = lb.transform(base_Treinamento[:,5])

classes = lb.fit_transform(base_Treinamento[:,8])

#Concatenação de Atributos (Colunas) 

#atributos_norm = np.column_stack((Pregnancies,Glucose))
print("--------------------------------")
print("Atributos de Entrada - Numéricos")
print("--------------------------------")
print(atributos_norm)

print("----------------------------------------")
print("Classificação Supervisionada - Numéricos")
print("----------------------------------------")
diagnostico_norm = np.hstack((classes))
print(diagnostico_norm)

"""### Treinamento do Neurônio Perceptron"""

from sklearn.linear_model import Perceptron
# Treinamento do Perceptron a partir dos atributos de entrada e classificações
modelo = Perceptron()
modelo.fit(atributos_norm, diagnostico_norm)

# Acurácia do modelo, que é : 1 - (predições erradas / total de predições)
# Acurácia do modelo: indica uma performance geral do modelo. 
# Dentre todas as classificações, quantas o modelo classificou corretamente;
# (VP+VN)/N
print('Acurácia: %.3f' % modelo.score(atributos_norm, diagnostico_norm))

"""### ----------------------------------------------------------------------------

# Validação do Aprendizado

### Predição a partir de base de dados (.csv)
"""

#import pandas as pd
# Carregando dados do arquivo CSV
#url = 'https://raw.githubusercontent.com/alcidesbenicasa/IA---2020.1---Exerc-cio---06---Rede-Neural-Artificial/main/dados_pacientes_teste.csv'
#base_Testes = pd.read_csv(url,sep=';', encoding = 'latin1').values

#test
base_Testes = pd.read_csv(url,sep=',', encoding = 'latin1', skiprows=650).values

print("----------------------------")
print("Dados dos Pacientes - TESTES")
print("----------------------------")
print(base_Testes)
print("---------------------------------")

# Extração dos Atributos a serem utilizadas pela rede
print("Atributos de Entrada")
print("---------------------------------")
print(base_Testes[:, 1:8])

"""### Pré-processamento de Dados"""

import numpy as np 
from sklearn import preprocessing

# Binarizador de rótulo
lb = preprocessing.LabelBinarizer()

#A saída da transformação é também conhecido como codificação 1-de-n
#Transforma valores categóricos equidistantes em valores binários equidistantes.
#Atributos categóricos com valores sim e não
X_train = np.array(base_Testes[:,1:8])
scaler = preprocessing.StandardScaler().fit(X_train)

#Concatenação de Atributos (Colunas) 
atributos_norm = scaler.transform(X_train)
print("--------------------------------")
print("Atributos de Entrada - Numéricos")
print("--------------------------------")
print(atributos_norm)

"""### Predição da Base"""

base_Predicao = modelo.predict((atributos_norm))
#for x in range(len(base_Predicao)):
#  print(x,":",base_Predicao[x])
print("Classificações: ", base_Predicao)

"""### Retorno aos valores Categóricos"""

import numpy as np 
from sklearn import preprocessing

# Binarizador de rótulo
lb = preprocessing.LabelBinarizer()

#A saída da transformação é também conhecido como codificação 1-de-n
#Transforma valores categóricos equidistantes em valores binários equidistantes.
#Atributos categóricos com valores sim e não

#lb.fit(base_Treinamento[:,0])
#Pregnancies = lb.inverse_transform(atributos_norm[:0])
#lb.fit(base_Treinamento[:,1])  
#Glucose = lb.inverse_transform(atributos_norm[:1])
#lb.fit(base_Treinamento[:,2])
#BloodPressure = lb.inverse_transform(atributos_norm[:2])
#lb.fit(base_Treinamento[:,3])
#SkinThickness = lb.inverse_transform(atributos_norm[:3])
#lb.fit(base_Treinamento[:,4])
#Insulin = lb.inverse_transform(atributos_norm[:4])
#lb.fit(base_Treinamento[:,5])
#BMI = lb.inverse_transform(atributos_norm[:5])
#lb.fit(base_Treinamento[:,6])
#DiabetesPedigreeFunction = lb.inverse_transform(atributos_norm[:6])
#lb.fit(base_Treinamento[:,7])
#Age = lb.inverse_transform(atributos_norm[:7])


#Concatenação de Atributos (Colunas) 
#atributos_cat = np.column_stack((Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,base_Testes[:8]))
print("--------------------------------")
print("Atributos de Entrada - Numéricos")
print("--------------------------------")
print(base_Treinamento)
print(base_Testes)